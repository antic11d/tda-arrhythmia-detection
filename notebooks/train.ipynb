{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten, MaxPooling1D, PReLU\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_x, train_y, test_x, test_y, dropout, epochs, batch_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, input_shape=(200, 1), padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(30))\n",
    "    model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    # evaluate model\n",
    "    loss, accuracy = model.evaluate(test_x, test_y, batch_size=batch_size, verbose=0)\n",
    "    return history, accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n228/228 [==============================] - 2s 11ms/step - loss: 1.8125 - accuracy: 0.6842\nEpoch 2/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.9948 - accuracy: 0.7982\nEpoch 3/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.9510 - accuracy: 0.7412\nEpoch 4/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.6693 - accuracy: 0.7939\nEpoch 5/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.6169 - accuracy: 0.8202\nEpoch 6/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.4300 - accuracy: 0.7982\nEpoch 7/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.7982\nEpoch 8/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.8246\nEpoch 9/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.4461 - accuracy: 0.8070\nEpoch 10/10\n228/228 [==============================] - 1s 3ms/step - loss: 0.4359 - accuracy: 0.8289\n"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/arrhythmia_sliced_10.csv')\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['class']\n",
    "y = to_categorical(y)\n",
    "\n",
    "X = np.expand_dims(X, axis=2)\n",
    "\n",
    "train_x, test_x, train_y, test_y = \\\n",
    "                    train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "train_history, test_accuracy, test_loss = evaluate_model(train_x, train_y, test_x, test_y, 0.5, 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train accuracy', 'train loss'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8585858345031738"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bittdaconda522e2e25bdc54781841ec8a5712db605",
   "display_name": "Python 3.8.2 64-bit ('tda': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}